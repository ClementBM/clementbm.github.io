---
layout: post
title:  "Compute simple corpus descriptive metrics"
excerpt: "Get a quick overview of a corpus with some basic descriptive metrics with the help of NLTK"
date:   2022-07-06
categories: [EDA, NLP, tokenizer]
tags: [NLTK, json]
---


![Multiple fruits](/assets/2022-07-06/pexels-trang-doan-1128678.jpg)

# Descriptive metrics

We define a corpus $$\mathcal{C} = {d_i} $$ as a list of document. The number of document can be seen as the cardinality of the corpus $$\vert \mathcal{C} \vert = N$$.

In this case, each document has only one text field, the title.

Each document has a set of text attribute/field. Each field is indexed with j from 1 to M, such $$a_{ij}$$ is the j$$^{th}$$ field of the i$$^{th}$$ document.

We define a tokenizer function $$ f_{tokenizer} $$ as $$ f_{tokenizer} : a_{ij} \rightarrow [t_1, ..., t_k, ... , t_L] $$, with $${t_k}$$ the list of tokens corresponding to the $$ a_{ij} $$ field.

We define $$ \mathcal{T} = t_{ijk} $$ the token k for the field j of the ith document.
We can also note $$ \mathcal{T}_j = t_{ik} $$ the list of token for a given field j.

We define the dictionary $$ \mathcal{D} = { t_i } $$ given a tokenizer function $$ f_{tokenizer} $$, as the list of unique tokens generated by a tokenizer on a given corpus.

| Metric | Formula | Tokenizer sensitive |
|--|--|--|
| Item Count | $$ \vert \mathcal{C} \vert $$ | No |
| Item Unique Count | $$ \vert \mathcal{C}_{unique} \vert $$ | No |
| Duplicate Item Proportion | $$ \vert \mathcal{C} \vert - \vert \mathcal{C}_{unique} \vert \over \vert \mathcal{C} \vert $$ | No |
| Dictionary Length | $$ \vert \mathcal{D} \vert $$ | Yes |
| Lemmatized Dictionary Length | $$ \vert \mathcal{D}_{lemme} \vert $$ | Yes |
| In vocabulary Token Proportion | $$ \vert \mathcal{D}_{lemme} \cap \mathcal{D}_{NLTK} \vert \over \vert \mathcal{D}_{lemme} \vert $$ | Yes |
| Out of vocabulary Token Proportion (wordnet vocabulary) <br> Domain specific metric | $$ \vert \mathcal{D}_{lemme} \vert - \vert \mathcal{D}_{lemme} \cap \mathcal{D}_{NLTK} \vert \over \vert \mathcal{D}_{lemme} \vert $$ | Yes |
| Token Count | $$ \vert \mathcal{T} \vert $$ | Yes |
| Lexical Diversity | $$ \vert \mathcal{D} \vert \over \vert \mathcal{T} \vert $$ | Yes |
| Hapaxes Proportion | $$ \vert \mathcal{D}_{hapax} \vert \over \vert \mathcal{D} \vert $$ | Yes |
| Uppercase Items Proportion | $$ n_{upper} \over n_{unique} $$ | No |
| Numerical Token Proportion | $$ d_{numerical} \over d $$ | Yes |
| Average Item Length | $$ \bar{n} $$ | Yes |
| Standard Deviation Item Length | $$ s_{n} $$ | Yes |
| Median Item Length | $$ \tilde{n} $$ | Yes |
| Minimum/Maximum Item Length | $$ min(n), max(n) $$ | Yes |

**Tokenizer specifications**

| Step | Description |
|--|--|
| Replace html entities | Remove html entities like &gt; or &nbsp; and convert them to their corresponding unicode character. |
| Find word according to regex patterns | |
| Filter (remove) words that are punctuation | remove punctuation from `string.punctuation` **'!"#$%&\'()*+,-./:;<=>?@[\\]^_`{\|}~'** and **——–’‘“”×** |


## Create a simple Corpus Metrics class

```python
"n" for nouns
"v" for verbs
"a" for adjectives
"r" for adverbs
"s" for satellite adjectives
```